import torch.nn as nn
from transformer.utils.multi_head_attention import MultiHeadAttention
from transformer.utils.feed_forward import FeedForward

'''The DecoderLayer class implements one of the decoder layers in the Transformer model. Its main goal is to generate rich 
representations for the output tokens, taking into account both the context of the previous output tokens and the representations 
generated by the encoder.'''
class DecoderLayer(nn.Module):
    def __init__(self, embedding_dimension, number_heads, feed_forward_dimension, dropout, use_cross_attention = True):
        super(DecoderLayer, self).__init__()

        self.use_cross_attention = use_cross_attention

        '''Self-attention allows an element in a sequence (such as a word or token) to pay attention to 
        other elements in the same sequence. This is crucial to capture dependencies within the same entry'''
        self.self_attention = MultiHeadAttention(embedding_dimension, number_heads)
        self.self_attention_normalizer = nn.LayerNorm(embedding_dimension)

        '''Cross-attention allows an element in one sequence (as in the decoder) to pay attention to elements 
        in another sequence (as in the encoder output). It is key in translation tasks, text generation, and 
        other cases where there are two related sequences'''
        if (self.use_cross_attention):
            self.cross_attention = MultiHeadAttention(embedding_dimension, number_heads)
            self.cross_attention_normalizer = nn.LayerNorm(embedding_dimension)

        '''It is a feed-forward network that is independently applied to each position in the sequence to learn 
        complex nonlinear transformations to enrich representations and complement the capacity of attention'''
        self.feed_forward = FeedForward(embedding_dimension, feed_forward_dimension)
        self.feed_forward_normalizer = nn.LayerNorm(embedding_dimension)

        '''Dropout introduces noise during training, forcing the network to learn more robust and generalizable 
        representations instead of overly relying on specific combinations of neurons'''
        self.dropout = nn.Dropout(dropout)

    def forward(self, decoder_output, decoder_output_mask, encoder_output = None, encoder_output_mask = None):
        attention_output = self.self_attention(decoder_output, decoder_output, decoder_output, decoder_output_mask)
        x = self.self_attention_normalizer(decoder_output + self.dropout(attention_output))

        if (self.use_cross_attention):
            attention_output = self.cross_attention(x, encoder_output, encoder_output, encoder_output_mask)
            x = self.cross_attention_normalizer(x + self.dropout(attention_output))

        feed_forward_output = self.feed_forward(x)
        x = self.feed_forward_normalizer(x + self.dropout(feed_forward_output))

        return x