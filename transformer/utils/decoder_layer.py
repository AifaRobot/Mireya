import torch.nn as nn
from transformer.utils.multi_head_attention import MultiHeadAttention
from transformer.utils.feed_forward import FeedForward

'''
    The DecoderLayer class implements one of the decoder layers in the Transformer model. Its main goal is to generate rich 
    representations for the output tokens, taking into account both the context of the previous output tokens and the representations 
    generated by the encoder.
'''
class DecoderLayer(nn.Module):
    def __init__(self, embedding_dimension, number_heads, feed_forward_dimension, dropout):
        super(DecoderLayer, self).__init__()
        
        # Self-attention allows an element in a sequence (such as a word or token) to pay attention to other elements in the same 
        # sequence. This is crucial to capture dependencies within the same entry
        self.self_attention = MultiHeadAttention(embedding_dimension, number_heads)
        
        # Cross-attention allows an element in one sequence (as in the decoder) to pay attention to elements in another sequence (as in 
        # the encoder output). It is key in translation tasks, text generation, and other cases where there are two related sequences
        self.cross_attention = MultiHeadAttention(embedding_dimension, number_heads)

        # It is a feed-forward network that is independently applied to each position in the sequence to learn complex nonlinear transformations 
        # to enrich representations and complement the capacity of attention
        self.feed_forward = FeedForward(embedding_dimension, feed_forward_dimension)

        # Normalization layers stabilize the learning process of the Decoder layers
        self.normalizer_layer_1 = nn.LayerNorm(embedding_dimension)
        self.normalizer_layer_2 = nn.LayerNorm(embedding_dimension)
        self.normalizer_layer_3 = nn.LayerNorm(embedding_dimension)
        
        # Dropout introduces noise during training, forcing the network to learn more robust and generalizable representations instead 
        # of overly relying on specific combinations of neurons
        self.dropout = nn.Dropout(dropout)

    def forward(self, x, encoder_output, src_mask, tgt_mask):
        attention_output = self.self_attention(x, x, x, tgt_mask)
        x = self.normalizer_layer_1(x + self.dropout(attention_output))
        attention_output = self.cross_attention(x, encoder_output, encoder_output, src_mask)
        x = self.normalizer_layer_2(x + self.dropout(attention_output))
        feed_forward_output = self.feed_forward(x)
        x = self.normalizer_layer_3(x + self.dropout(feed_forward_output))
        
        return x